\chapter{Υπόβαθρο}\label{chap:background}
Στο κεφάλαιο αυτό παρουσιάζεται το θεωρητικό υπόβαθρο που σχετίζεται με την παρούσα εργασία.
Περιγράφονται περιληπτικά βασικές ιδέες και έννοιες σχετικές με τη μηχανική εκμάθηση και την κατανόηση φυσικής γλώσσας.

Η έννοια της μάθησης συνδέεται με την ικανότητα ενός προγράμματος να βελτιώνει με την επανάληψη και την πρόσκτηση επιπλέον γνώσης την απόδοσή του.
Αποτελεί πεδίο μελέτης που δίνει στους υπολογιστές την ικανότητα να μαθαίνουν, χωρίς να έχουν ρητά προγραμματιστεί~\cite{samuel1959some}.
Στο~\cite{mitchell1990machine}, η \newterm{Μηχανική Εκμάθηση}{Machine Learning - ML} ορίζεται πιο συγκεκριμένα ως:
\begin{framed}
    Λέμε ότι ένα πρόγραμμα μαθαίνει από την υπάρχουσα εμπειρία $E$ αναφορικά με κάποια εργασία $T$ που πρέπει να επιτελέσει και με κάποιο μέτρο απόδοσης $P$,
    όταν η απόδοση του στην εργασία $T$, όπως μετριέται από το $P$, βελτιώνεται από την εμπειρία $E$.%
\end{framed}

\ig[type=pgf]{ml-trends}{\lcaption{Τάσεις όρων σχετικών με τη μηχανική εκμάθηση}{%
        Από \en{Google trends}: \url{https://trends.google.com/}.%
    }%
}

Παραδοσιακά, η μηχανική εκμάθηση μπορεί να χωριστεί σε τρεις κατηγορίες~\cite{goodfellow}:
\begin{enumerate}
    \item \newtermc{Μάθηση με Επίβλεψη}{Supervised Learning}:
          Οι αλγόριθμοι μάθησης με επίβλεψη αποκτούν εμπειρία πάνω σε ένα σύνολο δεδομένων που περιέχει διάφορα χαρακτηριστικά και κάθε στοιχείο του συνοδεύεται από κάποια ετικέτα ή στόχο.
          Ονομάζονται έτσι λόγω του ότι η έξοδος $\vy$ του αλγόριθμου παρέχεται από κάποιο \enquote{δάσκαλο} που δείχνει στο σύστημα μηχανικής εκμάθησης τι να κάνει.
          Οι αλγόριθμοι αυτοί παρατηρούν πολλές πιθανές τιμές ενός τυχαίου διανύσματος $\vx$ και το αντίστοιχο διάνυσμα εξόδου $\vy$ και μαθαίνουν πώς να προβλέπουν το $\vy$ από το $\vx$,
          συνήθως υπολογίζοντας την υπό συνθήκη πιθανότητα $p(\vy \mid \vx)$.

          Ανάλογα με τον τύπο της εξόδου $\vy$, συνήθως τα προβλήματα της μάθησης με επίβλεψη διακρίνονται σε αυτά της παλινδρόμησης και αυτά της ταξινόμησης.
          \begin{itemize}
              \item Στην \newterm[Μάθηση με Επίβλεψη - Supervised Learning]{Παλινδρόμηση}{Regression}
                    ζητείται από τον αλγόριθμο εκμάθησης να εξάγει μία συνάρτηση $f : \mathbb{R}^n \mapsto \mathbb{R}$
                    (ή κάποιο άλλο συνεχές υποσύνολο του $\mathbb{R}$),
                    δηλαδή να υπολογίζεται μια αριθμητική τιμή δεδομένου του διανύσματος εισόδου.
                    Παράδειγμα τέτοιου προβλήματος αποτελεί η πρόβλεψη της ζήτησης του ηλεκτρικού φορτίου σε ένα δίκτυο διανομής ηλεκτρικής ενέργειας.

                    Όταν η συνάρτηση $f : \mathbb{R}^n \mapsto \mathbb{R}^k$ αντιστοιχίζει κάθε τιμή εισόδου σε ένα διάνυσμα $\vy$ διάστασης $k$,
                    το πρόβλημα ονομάζεται \newterm{Παλινδρόμηση Πολλών Εξόδων}{Multioutput Regression}.

              \item Στην \newterm[Μάθηση με Επίβλεψη - Supervised Learning]{Ταξινόμηση}{Classification}
                    ή \newtermsee[Μάθηση με Επίβλεψη - Supervised Learning]{Κατηγοριοποίηση}{}{Ταξινόμηση}
                    το μοντέλο αντιστοιχίζει την είσοδο σε μια διακριτή τιμή εξόδου.
                    Συνήθως, παράγεται μια συνάρτηση $f : \mathbb{R}^n \mapsto \{1 \ldots k\}$ της οποίας η είσοδος αντιστοιχίζεται μια κατηγορία ή κλάση.
                    Όταν υπάρχουν μόνο δύο πιθανές κλάσεις, $k = 2$, το πρόβλημα ονομάζεται
                    \newterm[Μάθηση με Επίβλεψη - Supervised Learning!Ταξινόμηση - Classification]{Δυαδική\dd{ς ταξινόμησης}}{Binary\dd{ Classification}}.
                    Αντίθετα, όταν υπάρχουν περισσότερες από δύο κλάσεις, $k > 2$, το πρόβλημα ονομάζεται
                    \newterm[Μάθηση με Επίβλεψη - Supervised Learning!Ταξινόμηση - Classification]{Πολλών Κλάσεων}{Multiclass\dd{ Classification}}
                    ή \newtermsee[Μάθηση με Επίβλεψη - Supervised Learning!Ταξινόμηση - Classification]{Πολυωνυμική\dd{ς} Ταξινόμηση\dd{ς}}{Multinomial\dd{ Classification}}{Πολλών Κλάσεων}.
                    Πολλοί ταξινομητές είναι εκ φύσεως δυαδικοί και απαιτούν διάφορες στρατηγικές για τη μετατροπή τους σε ταξινομητές πολλαπλών κλάσεων.

                    Επίσης, όταν η συνάρτηση $f : \mathbb{R}^n \mapsto 2^{\{1 \ldots k\}}$ αντιστοιχίζει κάθε τιμή εισόδου σε ένα υποσύνολο του συνόλου κλάσεων $\{1 \ldots k\}$, το πρόβλημα ονομάζεται
                    \newterm[Μάθηση με Επίβλεψη - Supervised Learning!Ταξινόμηση - Classification]{Πολλών Ετικετών}{Multi-Label\dd{ Classification}}.
                    Μπορούμε να πούμε ότι η $f : \mathbb{R}^n \mapsto {\{0, 1\}}^k$ αντιστοιχίζει την είσοδο σε ένα $k$-διάστατο δυαδικό διάνυσμα $y$ όπου κάθε στοιχείο του αντιστοιχεί σε μια από τις $k$ ετικέτες.
          \end{itemize}

    \item \newtermc{Μάθηση χωρίς Επίβλεψη}{Unsupervised Learning}:
          % Unsupervised learning algorithms experience a dataset containing many features, then learn useful properties of the structure of this dataset.
          Οι αλγόριθμοι μάθησης χωρίς επίβλεψη αποκτούν εμπειρία πάνω σε ένα σύνολο δεδομένων που περιέχει διάφορα χαρακτηριστικά και μαθαίνουν χρήσιμες ιδιότητες σχετικά με τη δομή αυτού του συνόλου δεδομένων.
          % In unsupervised learning, there is no instructor or teacher, and the algorithm must learn to make sense of the data without this guide.
          Σε αυτόν τον τύπο μάθησης, δεν υπάρχει \enquote{δάσκαλος} και ο αλγόριθμος πρέπει να μάθει να βγάζει νόημα από τα δεδομένα χωρίς οδηγό.
          % Roughly speaking, unsupervised learning involves observing several examples of a random vector x, and attempting to implicitly or explicitly learn the probability distribution p(x), or some interesting properties of that distribution.
          Παρατηρεί πολλές πιθανές τιμές ενός τυχαίου διανύσματος $x$ και προσπαθεί να μάθει την κατανομή πιθανότητας $p(x)$ ή κάποιες άλλες χρήσιμες ιδιότητές της.

    \item \newtermc{Ενισχυτική Μάθηση}{Reinforcement Learning}:
          Ένα πρόγραμμα υπολογιστή αλληλεπιδρά με ένα δυναμικό περιβάλλον στο οποίο πρέπει να επιτευχθεί ένας συγκεκριμένος στόχος (όπως η οδήγηση ενός οχήματος ή η νίκη σε μια παρτίδα σκάκι),
          χωρίς κάποιος δάσκαλος να του λέει ρητά αν έχει φτάσει κοντά στον στόχο του αλλά μέσω της μεθόδου της \enquote{δοκιμής και λάθους}.
\end{enumerate}

Από εδώ και στο εξής θα αναφερόμαστε μόνο σε αλγορίθμους μηχανικής μάθησης με επίβλεψη εκτός και αν αναφέρεται ρητά το αντίθετο.

\input{./2/machine_learning.tex}
\input{./2/natural_language.tex}

% vim:ts=4:sw=4:expandtab:fo-=tc:tw=120
